{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For this task we will use a 'urllib' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the liberary \n",
    "import urllib.request , urllib.parse, urllib.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "#open a connection between python  and web page.\n",
    "fhand=urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "#looping through the text to print lines \n",
    "for line in fhand :\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the count of different words in the text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "fhand=urllib.request.urlopen('http://data.pr4e.org/romeo.txt') \n",
    "counts=dict()\n",
    "for line in fhand :\n",
    "    words =line.decode().split()\n",
    "    for word in words :\n",
    "        counts[word]=counts.get(word,0)+1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing HTML using regual expression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__An example to retrieve links from kaggle page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_links():\n",
    "    url =input('Enter the the URL you want to parse')\n",
    "    html =urllib.request.urlopen(url).read()\n",
    "    \n",
    "    links =re.findall(b'href=\"(https://.*?)\"',html)\n",
    "    for link in links:\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the the URL you want to parsehttps://www.kaggle.com/alxmamaev/flowers-recognition/kernels\n",
      "b'https://www.google-analytics.com'\n",
      "b'https://stats.g.doubleclick.net'\n",
      "b'https://js.intercomcdn.com'\n",
      "b'https://storage.googleapis.com'\n",
      "b'https://apis.google.com'\n",
      "b'https://fonts.googleapis.com/icon?family=Google+Material+Icons'\n"
     ]
    }
   ],
   "source": [
    "find_links()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
